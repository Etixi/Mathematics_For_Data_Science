# 130 termes de Sciences de données que tout scientifique devraient connaitre en 2024


## A

**1. Tests A/B :** Méthode statistique utilisée pour comparer deux versions d'un produit, d'une page Web ou d'un modèle afin de déterminer laquelle est la plus performante.

<br/>

**2. Précision :** mesure de la fréquence à laquelle un modèle de classification prédit correctement les résultats parmi toutes les instances qu'il évalue.

<br/>

**3. Adaboost :** Un algorithme d'apprentissage d'ensemble qui combine des classificateurs faibles pour créer un classificateur fort.

<br/>

**4. Algorithme :** Un ensemble d'instructions ou de règles étape par étape suivies par un ordinateur pour résoudre un problème ou effectuer une tâche.

<br/>

**5. Analytics :** processus d'interprétation et d'examen des données pour en extraire des informations significatives.

<br/>

**6. Détection des anomalies :** identification de modèles inhabituels ou de valeurs aberrantes dans les données.

<br/>

**7. ANOVA (Analyse de Variance) :** Méthode statistique utilisée pour analyser les différences entre les moyennes des groupes dans un échantillon.

<br/>

**8. API (Application Programming Interface) :** Un ensemble de règles qui permettent à une application logicielle d'interagir avec une autre.

<br/>

**9. AUC-ROC (Area Under the ROC Curve) :** Une métrique qui nous indique dans quelle mesure un modèle de classification fonctionne globalement, en considérant différentes manières de décider ce qui compte comme une prédiction positive ou négative.

# B


**10. Descente de gradient par lots :** un algorithme d'optimisation qui met à jour les paramètres du modèle en utilisant l'ensemble des données d'entraînement (différent de la descente de gradient par mini-lots )

<br/>

**11. Statistiques bayésiennes :** une approche statistique qui combine des connaissances antérieures et des données observées.

<br/>

**12. BI (Business Intelligence) :** Technologies, processus et outils qui aident les organisations à prendre des décisions commerciales éclairées.

<br/>

**13. Biais :** erreur dans un modèle qui l'amène à prédire systématiquement des valeurs éloignées des valeurs réelles.

<br/>

**14. Compromis biais-variance :** l'équilibre entre l'erreur introduite par le biais et la variance dans un modèle.

<br/>

**15. Big Data :** ensembles de données volumineux et complexes qui ne peuvent pas être facilement traités à l'aide des méthodes de traitement de données traditionnelles.

<br/>

**16. Classification binaire :** catégoriser les données en deux groupes, tels que spam ou non spam.

<br/>

**17. Échantillonnage bootstrap :** technique de rééchantillonnage dans laquelle des échantillons aléatoires sont tirés avec remplacement à partir d'un ensemble de données.

# C
**18. Données catégorielles :** variables qui représentent des catégories ou des groupes et peuvent prendre un nombre limité et fixe de valeurs distinctes.

<br/>

**19. Test du Chi carré :** Un test statistique utilisé pour déterminer s'il existe une association significative entre deux variables catégorielles.

<br/>

**20. Classification :** Catégorisation des points de données en classes ou groupes prédéfinis.

<br/>

**21. Clustering :** regroupement de points de données similaires en fonction de certains critères.

<br/>

**22. Intervalle de confiance :** une plage de valeurs utilisée pour estimer la valeur réelle d'un paramètre avec un certain niveau de confiance.

<br/>

**23. Matrice de confusion :** Tableau utilisé pour évaluer les performances d'un algorithme de classification.

<br/>

**24. Corrélation :** Une mesure statistique qui décrit le degré d'association entre deux variables.

<br/>

**25. Covariance :** mesure de la mesure dans laquelle deux variables aléatoires changent ensemble.

<br/>

**26. Perte d'entropie croisée :** fonction de perte couramment utilisée dans les problèmes de classification.

<br/>

**27. Validation croisée :** technique permettant d'évaluer les performances d'un modèle en divisant les données en plusieurs sous-ensembles pour la formation et les tests.

# D

**28. Nettoyage des données :** processus d'identification et de correction des erreurs ou des incohérences dans les ensembles de données.

<br/>

**29. Exploration de données :** extraire des modèles ou des informations précieuses à partir de grands ensembles de données.

<br/>

**30. Prétraitement des données :** nettoyage et transformation des données brutes dans un format adapté à l'analyse.

<br/>

**31. Visualisation des données :** présentation des données dans des formats graphiques ou visuels pour faciliter la compréhension.

<br/>

**32. Limite de décision :** la ligne de démarcation qui sépare les différentes classes dans un problème de classification.

<br/>

**33. Arbre de décision :** un modèle arborescent qui prend des décisions basées sur un ensemble de règles.

<br/>

**34. Réduction de la dimensionnalité :** Réduire le nombre d'entités dans un ensemble de données tout en conservant les informations importantes.

# E

**35. Valeur propre et vecteur propre :** concepts utilisés en algèbre linéaire, souvent utilisés dans la réduction de dimensionnalité pour transformer et simplifier des ensembles de données complexes.

<br/>

**36. Elastic Net :** Une technique de régularisation qui combine les pénalités L1 et L2.

<br/>

**37. Apprentissage d'ensemble :** combinaison de plusieurs modèles pour améliorer les performances et la précision globales.

<br/>

**38. Analyse exploratoire des données (EDA) :** analyser et visualiser les données pour comprendre leurs caractéristiques et leurs relations.

# F

**39. F1 Score :** Une métrique qui combine précision et rappel dans les modèles de classification.

<br/>

**40. Faux positif et faux négatif :** prédictions incorrectes dans la classification binaire.

<br/>

**41. Fonctionnalité :** colonne de données utilisée comme entrée pour les modèles ML pour effectuer des prédictions.

<br/>

**42. Ingénierie des fonctionnalités :** création de nouvelles fonctionnalités à partir de celles existantes pour améliorer les performances du modèle.

<br/>

**43. Extraction de fonctionnalités :** réduire la dimensionnalité des données en sélectionnant des fonctionnalités importantes.

<br/>

**44. Importance des fonctionnalités :** évaluer la contribution de chaque fonctionnalité aux prédictions du modèle.

<br/>

**45. Sélection des fonctionnalités :** choisir les fonctionnalités les plus pertinentes pour un modèle.

# G

**46. Distribution gaussienne :** Un type de distribution de probabilité souvent utilisé dans la modélisation statistique.

<br/>

**47. Analyse géospatiale :** analyser et interpréter les modèles et les relations au sein des données géographiques.

<br/>

**48. Gradient Boosting :** Une technique d'apprentissage d'ensemble où les modèles faibles sont formés séquentiellement, chacun corrigeant les erreurs du précédent.

<br/>

**49. Descente de gradient :** algorithme d'optimisation utilisé pour minimiser l'erreur dans un modèle en ajustant ses paramètres.

<br/>

**50. Recherche de grille :** une méthode de réglage des hyperparamètres en évaluant les modèles dans toutes les combinaisons possibles.

# H

**51. Hétéroscédasticité :** Variabilité inégale des erreurs dans un modèle de régression.

<br/>

**52. Clustering hiérarchique :** méthode d'analyse de cluster qui organise les données dans une structure arborescente de clusters, où chaque niveau de l'arborescence montre les relations et les similitudes entre différents groupes de points de données.

<br/>

**53. Hyperparamètre :** paramètre dont la valeur est définie avant le début du processus de formation.

<br/>

**54. Test d'hypothèse :** méthode statistique permettant de tester une hypothèse concernant un paramètre de population sur la base de données d'échantillonnage.


# I

**55. Imputation :** Remplir les valeurs manquantes dans un ensemble de données à l'aide de diverses techniques.

<br/>

**56. Statistiques inférentielles :** branche des statistiques qui consiste à faire des déductions sur une population sur la base d'un échantillon de données.

<br/>

**57. Gain d'information :** mesure utilisée dans les arbres de décision pour évaluer l'efficacité d'une fonctionnalité dans la classification des données.

<br/>

**58. Interquartile Range (IQR) :** mesure de la dispersion statistique, représentant l'intervalle entre le premier et le troisième quartile.

# J.

**59. Joint Plot :** Un type de visualisation de données dans Seaborn utilisé pour explorer les relations entre deux variables et leurs distributions individuelles.

<br/>

**60. Probabilité conjointe :** probabilité que deux événements ou plus se produisent en même temps, souvent utilisée dans l'analyse statistique.

<br/>

**61. Jupyter Notebook :** une application Web open source permettant de créer et de partager des documents contenant du code en direct, des équations, des visualisations et du texte narratif.

# K

**62. K-Means Clustering :** un algorithme populaire pour partitionner un ensemble de données en sous-ensembles distincts et ne se chevauchant pas.

<br/>

**63. K-Nearest Neighbours (KNN) :** un algorithme de classification simple et largement utilisé basé sur la proximité d'un nouveau point de données par rapport à d'autres points de données.

# L
**64. Régularisation L1 :** Ajout des valeurs absolues des coefficients comme terme de pénalité à la fonction de perte.

<br/>

**65. Régularisation L2 (Ridge) :** Ajout des valeurs au carré des coefficients comme terme de pénalité à la fonction de perte.

<br/>

**66. Régression linéaire :** méthode statistique permettant de modéliser la relation entre une variable dépendante et une ou plusieurs variables indépendantes.

<br/>

**67. Log de vraisemblance :** logarithme de la fonction de vraisemblance, souvent utilisé dans l'estimation du maximum de vraisemblance.

<br/>

**68. Fonction logistique :** fonction sigmoïde utilisée dans la régression logistique pour modéliser la probabilité d'un résultat binaire.

<br/>

**69. Régression logistique :** Une méthode statistique pour prédire la probabilité d'un résultat binaire.

# M

**70. Apprentissage automatique** : un sous-ensemble de l'intelligence artificielle qui permet aux systèmes d'apprendre et de faire des prédictions à partir de données.

<br/>

**71. Erreur absolue moyenne (MAE)** : mesure des différences absolues moyennes entre les valeurs prédites et réelles.

<br/>

**72. Erreur quadratique moyenne (MSE)** : mesure de la différence quadratique moyenne entre les valeurs prédites et réelles.

<br/>

**73. Moyenne** : la valeur moyenne d'un ensemble de nombres.

<br/>

**74. Médiane** : La valeur médiane dans un ensemble de nombres triés.

<br/>

**75. Métriques** : critères utilisés pour évaluer les performances d'un modèle d'apprentissage automatique, tels que l'exactitude, la précision, le rappel et le score F1.

<br/>

**76. Évaluation du modèle** : évaluer les performances d'un modèle d'apprentissage automatique à l'aide de diverses mesures.

<br/>

**77. Multicolinéarité** : Présence d'une forte corrélation entre des variables indépendantes dans un modèle de régression.

<br/>

**78. Classification multi-étiquettes** : attribution de plusieurs étiquettes à une entrée, par opposition à une seule.

<br/>

**79. Analyse multivariée** : analyser des données avec plusieurs variables pour comprendre les relations entre elles.

# N

**80. Naive Bayes** : Un algorithme probabiliste basé sur le théorème de Bayes utilisé pour la classification.

<br/>

**81. Normalisation** : mise à l'échelle des variables numériques dans une plage standard.

<br/>

**82. Hypothèse nulle** : une hypothèse statistique qui suppose qu'il n'y a pas de différence significative entre les résultats observés et attendus.

# O

**83. One-Hot Encoding** : Une technique pour convertir des variables catégorielles en une matrice binaire pour les modèles d'apprentissage automatique.

<br/>

**84. Variable ordinale** : Une variable catégorielle avec un ordre significatif mais pas nécessairement des intervalles égaux.

<br/>

**85. Valeur aberrante** : une observation qui s'écarte considérablement des autres observations dans un ensemble de données.

<br/>

**86. Surajustement** : un modèle qui fonctionne bien sur les données d'entraînement mais peu sur les nouvelles données invisibles.

# P.

**87. Pandas** : Une bibliothèque standard de manipulation de données pour Python pour travailler avec des données structurées.

<br/>

**88. Coefficient de corrélation de Pearson** : mesure de la relation linéaire entre deux variables.

<br/>

**89. Distribution de Poisson** : distribution de probabilité discrète qui exprime la probabilité qu'un nombre donné d'événements se produisent dans un intervalle de temps ou d'espace fixe.

<br/>

**90. Précision** : rapport entre les véritables prédictions positives et le nombre total de prédictions positives réalisées par un modèle de classification.

<br/>

**91. Analyse prédictive** : utilisation de données, d'algorithmes statistiques et de techniques d'apprentissage automatique pour identifier la probabilité de résultats futurs.

<br/>

**92. Analyse en composantes principales (ACP)** : Une technique de réduction de dimensionnalité qui transforme les données en un nouveau cadre de fonctionnalités, simplifiant l'information tout en préservant ses modèles fondamentaux.

<br/>

**93. Composante principale** : l'axe qui capture le plus de variance dans un ensemble de données dans l'analyse en composantes principales.

<br/>

**94. Valeur P** : probabilité d'obtenir un résultat aussi extrême, voire plus extrême, que le résultat observé lors du test d'hypothèse.

# Q
**95. QQ Plot (Quantile-Quantile Plot)** : Un outil graphique pour évaluer si un ensemble de données suit une distribution théorique particulière.

<br/>

**96. Quantile** : un point de données ou un ensemble de points de données qui divisent un ensemble de données en parties égales.

# R.

**97. Random Forest** : Une méthode d'apprentissage d'ensemble qui construit une multitude d'arbres de décision et les fusionne pour des prédictions plus précises et plus stables.

<br/>

**98. Échantillon aléatoire** : Un échantillon dans lequel chaque membre de la population a une chance égale d'être sélectionné.

<br/>

**99. Variable aléatoire** : Une variable dont les valeurs possibles sont le résultat d'un phénomène aléatoire.

<br/>

**100. Rappel** : le rapport entre les prédictions réellement positives et le nombre total d'instances positives réelles dans un modèle de classification.

<br/>

**101. Analyse de régression** : méthode statistique utilisée pour modéliser la relation entre une variable dépendante et une ou plusieurs variables indépendantes.

<br/>

**102. Régularisation** : ajout d'un terme de pénalité à la fonction de coût pour éviter le surajustement dans les modèles d'apprentissage automatique.

<br/>

**103. Rééchantillonnage** : techniques telles que le bootstrap ou la validation croisée pour évaluer les performances d'un modèle.

<br/>

**104. Courbe ROC (Receiver Operating Characteristic Curve)** : représentation graphique du compromis entre le taux de vrais positifs et le taux de faux positifs pour différents seuils dans un modèle de classification.

<br/>

**105. Erreur quadratique moyenne (RMSE)** : mesure de la différence entre les valeurs prédites et réelles.

<br/>

**106. R au carré** : mesure statistique qui représente la proportion de la variance de la variable dépendante expliquée par les variables indépendantes dans un modèle de régression.

# S

**107. Biais d'échantillonnage :** biais dans la sélection des participants ou des points de données qui peut affecter la généralisabilité des résultats.

<br/>

**108. Échantillonnage :** processus de sélection d'un sous-ensemble de points de données à partir d'un ensemble de données plus vaste.

<br/>

**109. Évolutivité :** capacité d'un système à gérer des quantités croissantes de données ou de charge de travail.

<br/>

**110. Fonction sigmoïde :** fonction mathématique utilisée dans les problèmes de classification binaire.

<br/>

**111. Silhouette Score :** une métrique utilisée pour calculer la qualité d'une technique de regroupement.

<br/>

**112. Décomposition en valeurs singulières (SVD) :** Une technique de factorisation matricielle utilisée dans la réduction de dimensionnalité.

<br/>

**113. Corrélation de rang de Spearman :** une mesure non paramétrique de corrélation entre deux variables.

<br/>

**114. Écart type :** mesure de l'ampleur de la variation ou de la dispersion dans un ensemble de valeurs.

<br/>

**115. Stationnarité :** Propriété des données de séries chronologiques où les propriétés statistiques restent constantes dans le temps.

<br/>

**116. Échantillonnage stratifié :** méthode d'échantillonnage qui garantit une représentation proportionnelle des sous-groupes au sein d'une population.

<br/>

**117. Apprentissage supervisé :** apprentissage à partir de données étiquetées où l'algorithme est formé sur un ensemble de paires d'entrées-sorties.

<br/>

**118. Support Vector Machine (SVM) :*** algorithme d'apprentissage automatique supervisé utilisé pour l'analyse de classification et de régression.

# T

**119. Distribution t :** distribution de probabilité utilisée dans les tests d'hypothèses lorsque la taille de l'échantillon est petite ou que l'écart type de la population est inconnu.

<br/>

**120. Analyse des séries chronologiques :** analyser les données collectées au fil du temps pour identifier les modèles et les tendances.

<br/>

**121. Test t :** Test statistique utilisé pour déterminer s'il existe une différence significative entre les moyennes de deux groupes.

<br/>

**122. Test t à deux échantillons :** test statistique utilisé pour comparer les moyennes de deux échantillons indépendants.

# U

**123. Sous-ajustement :** un modèle trop simple pour capturer les modèles sous-jacents dans les données.

<br/>

**124. Analyse univariée :** analyser la variation d'une seule variable dans l'ensemble de données.

<br/>

**125. Apprentissage non supervisé :** apprentissage à partir de données non étiquetées où l'algorithme identifie lui-même des modèles et des relations.

# V
**126. Ensemble de validation :** un sous-ensemble de données utilisé pour évaluer les performances d'un modèle pendant la formation.

<br/>

**127. Variance :** le degré de propagation ou de dispersion d'un ensemble de valeurs, ainsi que la variabilité des prédictions du modèle.

# X

**128. XGBoost :** Une bibliothèque open source pour les arbres de décision améliorés par gradient, conçus pour la vitesse et les performances.

# Z
**129. Zero-shot Learning :** entraîner un modèle à effectuer une tâche sans exemples explicites.

<br/>

**130. Z-Score :** un score standardisé qui représente le nombre d'écarts types entre un point de données et la moyenne.

<br/>

**Contribution des lecteurs**
---

<br/>

# C
**Fonction de coût :** résume les pertes individuelles dans tous les exemples de formation, guidant le modèle pour minimiser les erreurs pendant la formation.
# L
**Fonction de perte :** mesure la différence entre les valeurs prévues et réelles pour un seul exemple d'entraînement.
